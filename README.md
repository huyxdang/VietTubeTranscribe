# ğŸ‡»ğŸ‡³ Vietnamese Speech-to-Text Dataset (Conversational Podcasts)

This is a personal project to build a high-quality Vietnamese speech dataset (~20 hours) by downloading conversational podcast audio from YouTube, segmenting it, and manually transcribing each clip. Inspired by projects like [LJ Speech](https://keithito.com/LJ-Speech-Dataset/), this dataset is intended to support future research in ASR (automatic speech recognition) for low-resource languages.

---

## ğŸ“ Project Structure

viet-speech-dataset/
â”œâ”€â”€ downloads/ # Original downloaded audio (longform .wav)
â”œâ”€â”€ segments/ # Segmented audio clips (short clips for transcription)
â”œâ”€â”€ transcriptions/ # Transcribed clips (JSON/CSV format)
â”œâ”€â”€ app/ # Manual transcription tool (React/Streamlit)
â”œâ”€â”€ youtube_links.txt # List of 24 YouTube podcast URLs
â”œâ”€â”€ batch_download.sh # Script to download and extract audio
â””â”€â”€ README.md

---

## ğŸ”§ How It Works

### 1. ğŸ§² Download Audio
Put your YouTube podcast links (1 per line) in `youtube_links.txt`, then run:

```bash
bash batch_download.sh
This downloads audio-only .wav files into downloads/.

2. âœ‚ï¸ Segment by Silence
Use a script (e.g., with pydub or ffmpeg) to split long audio files into smaller clips based on silence. Save to segments/.

3. âœï¸ Manual Transcription
Use a simple web app to:

Play audio clips

Manually type in transcriptions

Save (audio_path, transcription) pairs to JSON/CSV

4. ğŸ“¦ Export Dataset
After labeling, export the data in a format like:

json
Copy
Edit
{
  "audio_filepath": "segments/clip_001.wav",
  "transcription": "Em chÃ o cÃ¡c báº¡n, hÃ´m nay chÃºng ta sáº½ nÃ³i vá»..."
}
ğŸ›  Tools & Stack
yt-dlp â€” audio download

ffmpeg â€” audio segmentation

React or Streamlit â€” transcription tool

Python â€” data preprocessing scripts

âœ¨ Status
âœ… ~20 hours of YouTube podcast downloaded

â³ Transcription tool in development

ğŸ“œ License
Currently for research/personal use only. Please contact xhuydng@gmail.com before using for commercial purposes.

ğŸ™‹â€â™‚ï¸ Author
Created by Huy Dang â€“ feel free to reach out for collaborations or ideas on low-resource language AI!